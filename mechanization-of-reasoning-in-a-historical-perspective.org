* Mechanization of Reasoning in a Historical Perspective

Started reading:
21 August 21 8:19 pm IST

The idea of formalization of reasoning starts from the middle ages and reached its maturity in modern logic that is in Frege → Peano → Russell and Whitehead → Hubert → Lukasiewicz → Gödel → Tarski → Jaśkowski → Leśniewski etc.

Elimination of quantifiers results in reducing whole of logic into binary algebra.

Formalization of logic effectively resulted in us pursuing inquiry into the nature of intelligence by providing us a suitable base.

Reasoning stands for deduction in this volume.

A thinking machine is an information-processing system that has a hardware component, the processing being aimed at growth of information; Information processing is found in a continuous interplay with data processing, the former being construed as operating on abstract objects (numbers, propositions, etc.), the latter as operating on physical tokes (e.g., numerals produced with ink, or by magnetization of some spots, etc.) which represent pieces of information.

Logic is the theory which deals with a special kind of information processing, namely that which preserves the truth of information.

Two sense of mechanization:

1/ Mechanization as synonymous with formalization. Formalization as in Post production systems, where you can deduce theorems through syntactic manipulations
2/ Mechanization in the narrow sense that there exists a device and a software to operate on it in order to process sentences (syntactically defined string of tokens) according to an algorithm involved in the given formalization.

Formalization or mechanization in the sense of 2/ consists in using a device and a mapping to this device of an abstract machine.

The work of Shannon in interpreting circuits as performing boolean logic allowed for the method of reducing predicate logic to propositional logic due to Skolem, Hubert, and others which enabled the use of binary digital circuitry for mechanizing proofs in predicate logic.

One more significant step in this direction is the cut-free formalisms of Herbrand and Gentzen of the predicate-calculus. The cut is a schema representing a number of inference rules, one of them being the familiar modus ponendo ponens, whose use in a proof requires some ingenuity on the side of the reasoner to identify the premises from which the conclusion is being cut must be found.

On the other hand, in a proof produced with the cut-free formalism, each step is determined by the syntactic structure of the formula processed, hence the need for intervention is extremely reduced, and the whole procedure becomes fairly mechanical.

Gentzen demonstrated that any proof involving the cut rule can be transformed into a proof in which the cut does not appear, and this implies availability of a mechanical procedure for any proof formalized in predicate logic.

CU = <Information + Data + Machines?;
       Natural Machine, Artificial Machine, Selves;
       Rec[d,i]
       PrI[i,j]
       PrD[d,e]
       PrT[t1,t2,i],
       Cns[s1,x]>


Rec[d,i]: Piece of data d is assigned the information i.
PrI[i,j]: Transforming information into pieces of information
PrD: Transforming data into data
PrT: Transforming Things into Things (or, a state of a thing into its another state) through a piece of information such as a dog acting to the command of a master.
CnS[s1,x]: Self conscious minds. A mind is capable of being conscious of any object whatever including its own acts. This kind of consciousness is called apperception.

*** 1.3 Information-processing through data processing

Information pieces are entities which are involved in the interaction between the physical world and the world of abstract entities.

What all information pieces have in common is their relation to some physical objects termed as data. The relation involved may be called expressing, representing, articulatin,g, formulating, signifying, recording etc.

Verb Recording is considered standard here.

Thus an uttered (spoken or written) sentence is a physical event being a datum to record a proposition. A score, as a sheet of paper covered with notes is a datum to record a piece of music. A drawing is a datum to record the design, say of a house. A configuration of polarized spots on a magnetic medium forms data to record, e.g., a program for computer.

To some extent, the elusiveness of the notion of IP can be remedied by a certain combination of the idea of recording relation with the concept of equivalence (or abstraction class) as defined in logic and set theory.

An equivalence relation is reflexive, symmetric, and transitive. Whenever one has an equivalence relation on a set S, the set can be partitioned into a number of disjoint sets called equivalence classes such that all the members of any one equivalent class bear the relation R to each other but not to any members of S outside that equivalence class.

Cardinal numbers are defined by reference to equivalence classes of equinumerous sets. E.g., number 2 is presented as the set of all pairs. This does not mean that the terms 2 and the class of all pairs denote the same entity. It is certainly true that # > 2 but this does not imply that triples is greater than the class of pairs, hence the respective arguments of the predicate ‘is greater than’ do not prove interchangeable.

The method of introducing abstract objects through equivalence classes, as exemplified above, especially to examine relations between information-processing and data-processing. The idea to be developed is to the effect that pieces of information are abstract entities, in a way assigned to respective equivalence classes of pieces of data.

Author is trying to establish a correspondence between two chains, that of data and that of entities represented by data. The most basic is the correspondence between numeral sequences as data and numbers as entities represented by such sequences. They belong to 2 different domains.
Successor operation turns a number 10 to 11 and in the codomain it turns the numerals ‘10’ into ‘11’. I think it might have been better if the author used the word encode to represent the act of transforming the semantics into the syntax.

The item represented is called an information item and the item used to encode this is called the data.

Data items are recorded in objects such as machines and organisms, and owing to these records information can be stored in objects and processed by them.

Information as the abstract entity and data as the physical entity.

Processing applied to information and data are not independent; they are so related that data-processing is a means of information-processing.

The term ‘sentence’ denote a physical object made from ink, or air waves, or electric impulses, etc. (while the terms ‘proposition’, or ‘statement’, or ‘judgment’ will never appear in this role).

Thus sentences belong to the category of data.

Information pieces recorded in sentences are called propositions, so sentences like 2 + 3 encoded in Roman numerals, Decimal, or Binary representation record the same proposition. Obviously, P is not identical with any of the members of the equivalence class E. Neither with E itself. Were it identical with E, then it would be sensible and true to say, e.g., that P contains the empty class which would be a kind of nonsennce.

Then there are information pieces which are abstract entities, each of them being associated with exactly one equivalence class of data.

The notion of blind thinking (caeca cogitatio) was used by Leibniz to indicate the mechanical deduction carried out by computers without a notion of the semantics(?) of say a collection of six objects dividing into two triples.